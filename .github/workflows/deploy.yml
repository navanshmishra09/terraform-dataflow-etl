name: Deploy Infrastructure and Run Dataflow Job

on:
  push:
    branches:
      - main

jobs:
  deploy:
    name: Apply Terraform and Trigger Dataflow Job
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}

      - name: Setup gcloud CLI
        uses: google-github-actions/setup-gcloud@v2

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init
        run: terraform -chdir=terraform init -input=false
      
      - name: Terraform Plan
        run: terraform -chdir=terraform plan -var="project_id=${{ secrets.GCP_PROJECT_ID }}" -out=tfplan
        
      - name: Terraform Apply
        run: terraform -chdir=terraform apply -auto-approve -var="project_id=${{ secrets.GCP_PROJECT_ID }}"

      # --------------------------
      # Build Flex Template
      # --------------------------
      - name: Build Dataflow Flex Template
        run: |
          gcloud dataflow flex-template build gs://devops-training-475116-raw-buckettt/templates/etl_pipeline_flex.json
            --sdk-language=PYTHON \
            --image-gcr-path "gcr.io/devops-training-475116/etl_pipeline_flex_image" \
            --metadata-file ./dataflow/metadata.json \
            --flex-template-base-image "gcr.io/dataflow-templates-base/python3-template-launcher-base" \
            --py-path ./dataflow \
            --env FLEX_TEMPLATE_PYTHON_PY_FILE=etl_pipeline.py




      # --------------------------
      # Run Flex Template
      # --------------------------
      - name: Run Dataflow Flex Template
        run: |
          gcloud dataflow flex-template run etl-pipeline-$(date +%Y%m%d%H%M%S) \
            --template-file-gcs-location gs://${{ secrets.GCP_PROJECT_ID }}-raw-buckettt/templates/etl_pipeline_flex.json \
            --region=${{ secrets.GCP_REGION }} \
            --parameters input=gs://${{ secrets.GCP_PROJECT_ID }}-raw-buckettt/custom_sales_dataset.csv \
            --parameters output=${{ secrets.GCP_PROJECT_ID }}:cleaned_sales_data.sales_cleaned
